"""
Telegram handlers for AI features (Phase 8).

Commands:
  /ask <question>    ‚Äî ask the AI about the project (RAG)
  /parse <text>      ‚Äî parse natural language for stage/expense info
  /backfill          ‚Äî backfill embeddings for historical messages

Message handlers:
  Voice messages     ‚Äî transcribe via Whisper and store
  Photo messages     ‚Äî describe via GPT-4 Vision and store

Every incoming user message (text, voice, image) is stored in the
messages table and embedded for semantic search.
"""

import logging

from aiogram import F, Router
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.types import Message as TgMessage

from bot.db import repositories as repo
from bot.db.models import MessageType
from bot.db.session import async_session_factory
from bot.services.ai_client import is_ai_configured
from bot.services.embedding_service import embed_and_store
from bot.services.media_service import build_message_text, process_image, process_voice
from bot.services.nlp_parser import parse_message as nlp_parse
from bot.services.rag_service import ask_project, build_project_context

logger = logging.getLogger(__name__)
router = Router(name="ai_handlers")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# HELPERS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


async def _resolve_project_for_storage(
    message: TgMessage,
) -> tuple[int | None, int | None]:
    """
    Resolve project and user for message storage (voice/photo/text).

    This is a lightweight resolver that does NOT show a picker.
    For storage, we silently pick the best project:
      - Group chat ‚Üí linked project
      - Private chat ‚Üí first (newest) project

    Returns (user_id, project_id) ‚Äî either can be None.
    """
    tg_user = message.from_user
    if tg_user is None:
        return None, None

    async with async_session_factory() as session:
        user = await repo.get_user_by_telegram_id(session, tg_user.id)
        if user is None:
            return None, None

        # Group chat: use linked project
        if message.chat.type in ("group", "supergroup"):
            project = await repo.get_project_by_telegram_chat_id(
                session, message.chat.id
            )
            return user.id, project.id if project else None

        # Private chat: use first (newest) project
        projects = await repo.get_user_projects(session, user.id)
        if projects:
            return user.id, projects[0].id

        return user.id, None


async def _store_and_embed_message(
    *,
    project_id: int | None,
    user_id: int | None,
    chat_id: str,
    message_id: str | None,
    message_type: MessageType,
    raw_text: str | None,
    file_ref: str | None,
    transcribed_text: str | None,
):
    """Store a message in DB and create an embedding if applicable."""
    async with async_session_factory() as session:
        msg = await repo.create_message(
            session,
            project_id=project_id,
            user_id=user_id,
            platform="telegram",
            platform_chat_id=chat_id,
            platform_message_id=message_id,
            message_type=message_type,
            raw_text=raw_text,
            file_ref=file_ref,
            transcribed_text=transcribed_text,
        )

        # Embed the canonical text if we have a project
        canonical = build_message_text(
            message_type=message_type.value,
            raw_text=raw_text,
            transcribed_text=transcribed_text,
        )
        if project_id and canonical:
            await embed_and_store(
                session,
                project_id=project_id,
                content=canonical,
                metadata={
                    "source": "message",
                    "message_id": msg.id,
                    "message_type": message_type.value,
                    "user_id": user_id,
                },
            )

        await session.commit()
        return msg


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# /ask ‚Äî RAG question answering
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(Command("ask"))
async def cmd_ask(message: TgMessage, state: FSMContext) -> None:
    """
    Answer a question about the project using RAG.

    Usage: /ask –ö–∞–∫–æ–π –±—é–¥–∂–µ—Ç –Ω–∞ —ç–ª–µ–∫—Ç—Ä–∏–∫—É?
    """
    tg_user = message.from_user
    if tg_user is None:
        return

    # Extract question text after /ask
    question = (message.text or "").strip()
    if question.startswith("/ask"):
        question = question[4:].strip()

    if not question:
        await message.answer(
            "‚ùì <b>–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å</b>\n\n"
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /ask &lt;–≤–∞—à –≤–æ–ø—Ä–æ—Å&gt;\n"
            "–ü—Ä–∏–º–µ—Ä: /ask –ö–∞–∫–æ–π –±—é–¥–∂–µ—Ç –Ω–∞ —ç–ª–µ–∫—Ç—Ä–∏–∫—É?"
        )
        return

    if not is_ai_configured():
        await message.answer(
            "‚ö†Ô∏è AI-—Å–µ—Ä–≤–∏—Å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.\n"
            "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Azure OpenAI."
        )
        return

    # Resolve project (group ‚Üí linked, private ‚Üí single/first)
    from bot.adapters.telegram.project_resolver import resolve_project
    from bot.adapters.telegram.fsm_states import ReportSelection

    resolved = await resolve_project(
        message, state,
        intent="ask",
        picker_state=ReportSelection.selecting_project,
    )
    if not resolved:
        return

    async with async_session_factory() as session:
        # Build project context
        report_data = await repo.get_project_full_report_data(
            session, resolved.id
        )
        project_ctx = build_project_context(report_data)

        # Send thinking indicator
        thinking_msg = await message.answer("ü§î –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...")

        # Get RAG answer
        answer = await ask_project(
            session,
            project_id=resolved.id,
            question=question,
            project_context=project_ctx,
        )

        # Edit the thinking message with the result
        try:
            await thinking_msg.edit_text(f"ü§ñ <b>–û—Ç–≤–µ—Ç:</b>\n\n{answer}")
        except Exception:
            await message.answer(f"ü§ñ <b>–û—Ç–≤–µ—Ç:</b>\n\n{answer}")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# /parse ‚Äî NLP stage/expense extraction
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(Command("parse"))
async def cmd_parse(message: TgMessage, state: FSMContext) -> None:
    """
    Parse natural language for stage/expense information.

    Usage: /parse –î–µ–º–æ–Ω—Ç–∞–∂ –∑–∞–π–º—ë—Ç 2 –Ω–µ–¥–µ–ª–∏: 3 –¥–Ω—è –ø–ª–∏—Ç–∫–∞, 4 –¥–Ω—è –æ–±–æ–∏
    """
    text = (message.text or "").strip()
    if text.startswith("/parse"):
        text = text[6:].strip()

    if not text:
        await message.answer(
            "üìù <b>–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞</b>\n\n"
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /parse &lt;–æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–±–æ—Ç&gt;\n"
            "–ü—Ä–∏–º–µ—Ä: /parse –î–µ–º–æ–Ω—Ç–∞–∂ –∑–∞–π–º—ë—Ç 2 –Ω–µ–¥–µ–ª–∏: "
            "3 –¥–Ω—è —É–±—Ä–∞—Ç—å –ø–ª–∏—Ç–∫—É, 4 –¥–Ω—è —Å–Ω—è—Ç—å –æ–±–æ–∏"
        )
        return

    if not is_ai_configured():
        await message.answer(
            "‚ö†Ô∏è AI-—Å–µ—Ä–≤–∏—Å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.\n"
            "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Azure OpenAI."
        )
        return

    thinking_msg = await message.answer("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ–∫—Å—Ç...")

    result = await nlp_parse(text)
    if result is None:
        await thinking_msg.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç.")
        return

    # Format the parsed result
    parts: list[str] = [f"üìä <b>–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞</b>\n"]
    parts.append(f"–ù–∞–º–µ—Ä–µ–Ω–∏–µ: <b>{result.intent}</b>")

    if result.raw_summary:
        parts.append(f"–†–µ–∑—é–º–µ: {result.raw_summary}")

    if result.stages:
        parts.append("\nüìã <b>–≠—Ç–∞–ø—ã:</b>")
        for stage in result.stages:
            days_str = f" ({stage.total_days} –¥–Ω.)" if stage.total_days else ""
            budget_str = f" ‚Äî –±—é–¥–∂–µ—Ç: {stage.estimated_budget:,.0f}‚ÇΩ" if stage.estimated_budget else ""
            parts.append(f"  ‚Ä¢ <b>{stage.stage_name}</b>{days_str}{budget_str}")
            for sub in stage.sub_stages:
                sub_days = f" ‚Äî {sub.days} –¥–Ω." if sub.days else ""
                parts.append(f"    ‚ó¶ {sub.name}{sub_days}")
            if stage.notes:
                parts.append(f"    üí¨ {stage.notes}")

    if result.expenses:
        parts.append("\nüí∞ <b>–†–∞—Å—Ö–æ–¥—ã:</b>")
        for exp in result.expenses:
            exp_type = "–º–∞—Ç–µ—Ä–∏–∞–ª—ã" if exp.is_materials else "—Ä–∞–±–æ—Ç–∞"
            parts.append(
                f"  ‚Ä¢ {exp.description} ‚Äî {exp.amount:,.0f}‚ÇΩ "
                f"({exp.category}, {exp_type})"
            )

    if result.status_update:
        parts.append(f"\nüìå <b>–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞:</b> {result.status_update}")

    try:
        await thinking_msg.edit_text("\n".join(parts))
    except Exception:
        await message.answer("\n".join(parts))


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# /backfill ‚Äî embed historical messages
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(Command("backfill"))
async def cmd_backfill(message: TgMessage, state: FSMContext) -> None:
    """
    Backfill embeddings for historical messages that don't have them yet.

    Owner-only command.
    """
    tg_user = message.from_user
    if tg_user is None:
        return

    if not is_ai_configured():
        await message.answer("‚ö†Ô∏è AI-—Å–µ—Ä–≤–∏—Å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")
        return

    # Resolve project
    from bot.adapters.telegram.project_resolver import resolve_project
    from bot.adapters.telegram.fsm_states import ReportSelection

    resolved = await resolve_project(
        message, state,
        intent="backfill",
        picker_state=ReportSelection.selecting_project,
    )
    if not resolved:
        return

    async with async_session_factory() as session:
        # Check role ‚Äî only owners can backfill
        roles = await repo.get_user_roles_in_project(
            session, resolved.user_id, resolved.id
        )
        from bot.db.models import RoleType
        if RoleType.OWNER not in roles:
            await message.answer("‚õî –¢–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª–µ—Ü –ø—Ä–æ–µ–∫—Ç–∞ –º–æ–∂–µ—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å –±—ç–∫—Ñ–∏–ª–ª.")
            return

        status_msg = await message.answer("‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π...")

        messages = await repo.get_messages_without_embeddings(
            session, resolved.id
        )
        if not messages:
            await status_msg.edit_text("‚úÖ –í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")
            return

        count = 0
        for msg in messages:
            canonical = build_message_text(
                message_type=msg.message_type.value,
                raw_text=msg.raw_text,
                transcribed_text=msg.transcribed_text,
            )
            if canonical:
                await embed_and_store(
                    session,
                    project_id=resolved.id,
                    content=canonical,
                    metadata={
                        "source": "backfill",
                        "message_id": msg.id,
                        "message_type": msg.message_type.value,
                        "user_id": msg.user_id,
                    },
                )
                count += 1

        await session.commit()

        await status_msg.edit_text(
            f"‚úÖ <b>–ë—ç–∫—Ñ–∏–ª–ª –∑–∞–≤–µ—Ä—à—ë–Ω</b>\n\n"
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {count}\n"
            f"–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π –±–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {len(messages)}"
        )


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Voice message handler
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(F.voice)
async def handle_voice_message(message: TgMessage) -> None:
    """
    Handle incoming voice messages.

    1. Download the voice file from Telegram
    2. Transcribe via Whisper
    3. Store the message with transcribed text
    4. Create an embedding
    """
    tg_user = message.from_user
    if tg_user is None:
        return

    voice = message.voice
    if voice is None:
        return

    user_id, project_id = await _resolve_project_for_storage(message)

    # Download and transcribe
    file_id = voice.file_id
    transcribed = None

    if is_ai_configured():
        try:
            from aiogram import Bot
            bot = Bot.get_current()
            if bot:
                file = await bot.get_file(file_id)
                if file.file_path:
                    result = await bot.download_file(file.file_path)
                    if result:
                        audio_bytes = result.read()
                        transcribed = await process_voice(
                            audio_bytes, filename="voice.ogg"
                        )
        except Exception as e:
            logger.error("Voice download/transcription failed: %s", e)

    # Store the message
    await _store_and_embed_message(
        project_id=project_id,
        user_id=user_id,
        chat_id=str(message.chat.id),
        message_id=str(message.message_id),
        message_type=MessageType.VOICE,
        raw_text=None,
        file_ref=file_id,
        transcribed_text=transcribed,
    )

    # Reply
    if transcribed:
        await message.reply(
            f"üé§ <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n{transcribed}"
        )
    else:
        await message.reply(
            "üé§ –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ."
            + ("" if is_ai_configured() else "\n‚ö†Ô∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (AI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω).")
        )


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Photo/image message handler
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(F.photo)
async def handle_photo_message(message: TgMessage) -> None:
    """
    Handle incoming photo messages.

    1. Get the largest photo resolution
    2. Download the image from Telegram
    3. Describe via GPT-4 Vision
    4. Store the message with AI description
    5. Create an embedding
    """
    tg_user = message.from_user
    if tg_user is None:
        return

    photos = message.photo
    if not photos:
        return

    # Get the largest photo
    photo = photos[-1]
    caption = message.caption

    user_id, project_id = await _resolve_project_for_storage(message)

    # Download and describe
    file_id = photo.file_id
    description = None

    if is_ai_configured():
        try:
            from aiogram import Bot
            bot = Bot.get_current()
            if bot:
                file = await bot.get_file(file_id)
                if file.file_path:
                    result = await bot.download_file(file.file_path)
                    if result:
                        image_bytes = result.read()
                        description = await process_image(
                            image_bytes, caption=caption
                        )
        except Exception as e:
            logger.error("Photo download/description failed: %s", e)

    # Combine caption + AI description
    transcribed = description
    if caption and description:
        transcribed = f"{caption}\n\n[AI –æ–ø–∏—Å–∞–Ω–∏–µ]: {description}"
    elif caption and not description:
        transcribed = caption

    # Store the message
    await _store_and_embed_message(
        project_id=project_id,
        user_id=user_id,
        chat_id=str(message.chat.id),
        message_id=str(message.message_id),
        message_type=MessageType.IMAGE,
        raw_text=caption,
        file_ref=file_id,
        transcribed_text=transcribed,
    )

    # Reply
    if description:
        reply = f"üì∏ <b>–û–ø–∏—Å–∞–Ω–∏–µ —Ñ–æ—Ç–æ:</b>\n{description}"
    elif caption:
        reply = "üì∏ –§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ."
    else:
        reply = (
            "üì∏ –§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ."
            + ("" if is_ai_configured() else "\n‚ö†Ô∏è –û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ (AI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω).")
        )

    await message.reply(reply)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Text message storage (runs on all text messages for embedding)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(F.text, flags={"store_message": True})
async def store_text_message(message: TgMessage) -> None:
    """
    Store every incoming text message for future RAG/embedding use.

    This handler stores the message but does NOT prevent other handlers
    from processing it. It runs with a flag to mark it as a storage handler.

    Note: This handler is registered with lower priority. It stores
    messages in the background without blocking the main response flow.
    """
    tg_user = message.from_user
    if tg_user is None:
        return

    # Skip commands ‚Äî they're handled by specific handlers
    text = message.text or ""
    if text.startswith("/"):
        return

    # Skip very short messages (single characters, etc.)
    if len(text.strip()) < 3:
        return

    user_id, project_id = await _resolve_project_for_storage(message)

    await _store_and_embed_message(
        project_id=project_id,
        user_id=user_id,
        chat_id=str(message.chat.id),
        message_id=str(message.message_id),
        message_type=MessageType.TEXT,
        raw_text=text,
        file_ref=None,
        transcribed_text=text,
    )
