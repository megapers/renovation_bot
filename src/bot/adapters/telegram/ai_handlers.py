"""
Telegram handlers for AI features (Phase 8).

Commands:
  /ask <question>    ‚Äî ask the AI about the project (RAG)
  /parse <text>      ‚Äî parse natural language for stage/expense info
  /backfill          ‚Äî backfill embeddings for historical messages
  /summary           ‚Äî summarize each participant's contributions

Message handlers:
  Voice messages     ‚Äî transcribe via Whisper and store
  Photo messages     ‚Äî describe via GPT-4 Vision and store

Every incoming user message (text, voice, image) is stored in the
messages table and embedded for semantic search.
"""

import logging

from aiogram import Bot, F, Router
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.types import Message as TgMessage

from bot.db import repositories as repo
from bot.db.models import MessageType
from bot.db.session import async_session_factory
from bot.services.ai_client import is_ai_configured
from bot.services.embedding_service import embed_and_store
from bot.services.media_service import build_message_text, process_image, process_voice
from bot.services.nlp_parser import parse_message as nlp_parse
from bot.services.rag_service import ask_project, build_project_context

logger = logging.getLogger(__name__)
router = Router(name="ai_handlers")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# HELPERS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


async def _resolve_project_for_storage(
    message: TgMessage,
) -> tuple[int | None, int | None]:
    """
    Resolve project and user for message storage (voice/photo/text).

    This is a lightweight resolver that does NOT show a picker.
    For storage, we silently pick the best project:
      - Group chat ‚Üí linked project
      - Private chat ‚Üí first (newest) project

    Returns (user_id, project_id) ‚Äî either can be None.
    """
    tg_user = message.from_user
    if tg_user is None:
        return None, None

    async with async_session_factory() as session:
        user = await repo.get_user_by_telegram_id(session, tg_user.id)
        if user is None:
            return None, None

        # Group chat: use linked project
        if message.chat.type in ("group", "supergroup"):
            project = await repo.get_project_by_telegram_chat_id(
                session, message.chat.id
            )
            return user.id, project.id if project else None

        # Private chat: use first (newest) project
        projects = await repo.get_user_projects(session, user.id)
        if projects:
            return user.id, projects[0].id

        return user.id, None


async def _store_and_embed_message(
    *,
    project_id: int | None,
    user_id: int | None,
    chat_id: str,
    message_id: str | None,
    message_type: MessageType,
    raw_text: str | None,
    file_ref: str | None,
    transcribed_text: str | None,
):
    """Store a message in DB and create an embedding if applicable."""
    async with async_session_factory() as session:
        msg = await repo.create_message(
            session,
            project_id=project_id,
            user_id=user_id,
            platform="telegram",
            platform_chat_id=chat_id,
            platform_message_id=message_id,
            message_type=message_type,
            raw_text=raw_text,
            file_ref=file_ref,
            transcribed_text=transcribed_text,
        )

        # Embed the canonical text if we have a project
        canonical = build_message_text(
            message_type=message_type.value,
            raw_text=raw_text,
            transcribed_text=transcribed_text,
        )
        if project_id and canonical:
            await embed_and_store(
                session,
                project_id=project_id,
                content=canonical,
                metadata={
                    "source": "message",
                    "message_id": msg.id,
                    "message_type": message_type.value,
                    "user_id": user_id,
                },
            )

        await session.commit()
        return msg


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# /ask ‚Äî RAG question answering
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(Command("ask"))
async def cmd_ask(message: TgMessage, state: FSMContext) -> None:
    """
    Answer a question about the project using RAG.

    Usage: /ask –ö–∞–∫–æ–π –±—é–¥–∂–µ—Ç –Ω–∞ —ç–ª–µ–∫—Ç—Ä–∏–∫—É?
    """
    tg_user = message.from_user
    if tg_user is None:
        return

    # Extract question text after /ask
    question = (message.text or "").strip()
    if question.startswith("/ask"):
        question = question[4:].strip()

    if not question:
        await message.answer(
            "‚ùì <b>–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å</b>\n\n"
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /ask &lt;–≤–∞—à –≤–æ–ø—Ä–æ—Å&gt;\n"
            "–ü—Ä–∏–º–µ—Ä: /ask –ö–∞–∫–æ–π –±—é–¥–∂–µ—Ç –Ω–∞ —ç–ª–µ–∫—Ç—Ä–∏–∫—É?"
        )
        return

    if not is_ai_configured():
        await message.answer(
            "‚ö†Ô∏è AI-—Å–µ—Ä–≤–∏—Å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.\n"
            "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Azure OpenAI."
        )
        return

    # Resolve project (group ‚Üí linked, private ‚Üí single/first)
    from bot.adapters.telegram.fsm_states import ReportSelection
    from bot.adapters.telegram.project_resolver import resolve_project

    resolved = await resolve_project(
        message, state,
        intent="ask",
        picker_state=ReportSelection.selecting_project,
    )
    if not resolved:
        return

    async with async_session_factory() as session:
        # Build project context
        report_data = await repo.get_project_full_report_data(
            session, resolved.id
        )
        project_ctx = build_project_context(report_data)

        # Send thinking indicator
        thinking_msg = await message.answer("ü§î –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...")

        # Get RAG answer
        answer = await ask_project(
            session,
            project_id=resolved.id,
            question=question,
            project_context=project_ctx,
        )

        # Edit the thinking message with the result
        try:
            await thinking_msg.edit_text(f"ü§ñ <b>–û—Ç–≤–µ—Ç:</b>\n\n{answer}")
        except Exception:
            await message.answer(f"ü§ñ <b>–û—Ç–≤–µ—Ç:</b>\n\n{answer}")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# /parse ‚Äî NLP stage/expense extraction
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(Command("parse"))
async def cmd_parse(message: TgMessage, state: FSMContext) -> None:
    """
    Parse natural language for stage/expense information.

    Usage: /parse –î–µ–º–æ–Ω—Ç–∞–∂ –∑–∞–π–º—ë—Ç 2 –Ω–µ–¥–µ–ª–∏: 3 –¥–Ω—è –ø–ª–∏—Ç–∫–∞, 4 –¥–Ω—è –æ–±–æ–∏
    """
    text = (message.text or "").strip()
    if text.startswith("/parse"):
        text = text[6:].strip()

    if not text:
        await message.answer(
            "üìù <b>–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞</b>\n\n"
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /parse &lt;–æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–±–æ—Ç&gt;\n"
            "–ü—Ä–∏–º–µ—Ä: /parse –î–µ–º–æ–Ω—Ç–∞–∂ –∑–∞–π–º—ë—Ç 2 –Ω–µ–¥–µ–ª–∏: "
            "3 –¥–Ω—è —É–±—Ä–∞—Ç—å –ø–ª–∏—Ç–∫—É, 4 –¥–Ω—è —Å–Ω—è—Ç—å –æ–±–æ–∏"
        )
        return

    if not is_ai_configured():
        await message.answer(
            "‚ö†Ô∏è AI-—Å–µ—Ä–≤–∏—Å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.\n"
            "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Azure OpenAI."
        )
        return

    thinking_msg = await message.answer("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ–∫—Å—Ç...")

    result = await nlp_parse(text)
    if result is None:
        await thinking_msg.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç.")
        return

    # Format the parsed result
    parts: list[str] = ["üìä <b>–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞</b>\n"]
    parts.append(f"–ù–∞–º–µ—Ä–µ–Ω–∏–µ: <b>{result.intent}</b>")

    if result.raw_summary:
        parts.append(f"–†–µ–∑—é–º–µ: {result.raw_summary}")

    if result.stages:
        parts.append("\nüìã <b>–≠—Ç–∞–ø—ã:</b>")
        for stage in result.stages:
            days_str = f" ({stage.total_days} –¥–Ω.)" if stage.total_days else ""
            budget_str = f" ‚Äî –±—é–¥–∂–µ—Ç: {stage.estimated_budget:,.0f}‚ÇΩ" if stage.estimated_budget else ""
            parts.append(f"  ‚Ä¢ <b>{stage.stage_name}</b>{days_str}{budget_str}")
            for sub in stage.sub_stages:
                sub_days = f" ‚Äî {sub.days} –¥–Ω." if sub.days else ""
                parts.append(f"    ‚ó¶ {sub.name}{sub_days}")
            if stage.notes:
                parts.append(f"    üí¨ {stage.notes}")

    if result.expenses:
        parts.append("\nüí∞ <b>–†–∞—Å—Ö–æ–¥—ã:</b>")
        for exp in result.expenses:
            exp_type = "–º–∞—Ç–µ—Ä–∏–∞–ª—ã" if exp.is_materials else "—Ä–∞–±–æ—Ç–∞"
            parts.append(
                f"  ‚Ä¢ {exp.description} ‚Äî {exp.amount:,.0f}‚ÇΩ "
                f"({exp.category}, {exp_type})"
            )

    if result.status_update:
        parts.append(f"\nüìå <b>–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞:</b> {result.status_update}")

    try:
        await thinking_msg.edit_text("\n".join(parts))
    except Exception:
        await message.answer("\n".join(parts))


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# /backfill ‚Äî embed historical messages
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(Command("backfill"))
async def cmd_backfill(message: TgMessage, state: FSMContext) -> None:
    """
    Backfill embeddings for historical messages that don't have them yet.

    Owner-only command.
    """
    tg_user = message.from_user
    if tg_user is None:
        return

    if not is_ai_configured():
        await message.answer("‚ö†Ô∏è AI-—Å–µ—Ä–≤–∏—Å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")
        return

    # Resolve project
    from bot.adapters.telegram.fsm_states import ReportSelection
    from bot.adapters.telegram.project_resolver import resolve_project

    resolved = await resolve_project(
        message, state,
        intent="backfill",
        picker_state=ReportSelection.selecting_project,
    )
    if not resolved:
        return

    async with async_session_factory() as session:
        # Check role ‚Äî only owners can backfill
        roles = await repo.get_user_roles_in_project(
            session, resolved.user_id, resolved.id
        )
        from bot.db.models import RoleType
        if RoleType.OWNER not in roles:
            await message.answer("‚õî –¢–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª–µ—Ü –ø—Ä–æ–µ–∫—Ç–∞ –º–æ–∂–µ—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å –±—ç–∫—Ñ–∏–ª–ª.")
            return

        status_msg = await message.answer("‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π...")

        messages = await repo.get_messages_without_embeddings(
            session, resolved.id
        )
        if not messages:
            await status_msg.edit_text("‚úÖ –í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")
            return

        count = 0
        for msg in messages:
            canonical = build_message_text(
                message_type=msg.message_type.value,
                raw_text=msg.raw_text,
                transcribed_text=msg.transcribed_text,
            )
            if canonical:
                await embed_and_store(
                    session,
                    project_id=resolved.id,
                    content=canonical,
                    metadata={
                        "source": "backfill",
                        "message_id": msg.id,
                        "message_type": msg.message_type.value,
                        "user_id": msg.user_id,
                    },
                )
                count += 1

        await session.commit()

        await status_msg.edit_text(
            f"‚úÖ <b>–ë—ç–∫—Ñ–∏–ª–ª –∑–∞–≤–µ—Ä—à—ë–Ω</b>\n\n"
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {count}\n"
            f"–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π –±–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {len(messages)}"
        )


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# /summary ‚Äî participant contribution summaries
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(Command("summary"))
async def cmd_summary(message: TgMessage, state: FSMContext) -> None:
    """
    Generate an AI summary of each participant's contributions.

    Usage: /summary
    """
    tg_user = message.from_user
    if tg_user is None:
        return

    if not is_ai_configured():
        await message.answer("‚ö†Ô∏è AI-—Å–µ—Ä–≤–∏—Å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")
        return

    from bot.adapters.telegram.fsm_states import ReportSelection
    from bot.adapters.telegram.project_resolver import resolve_project

    resolved = await resolve_project(
        message, state,
        intent="summary",
        picker_state=ReportSelection.selecting_project,
    )
    if not resolved:
        return

    status_msg = await message.answer("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∫–ª–∞–¥ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤...")

    from bot.services.participant_service import summarize_all_participants

    async with async_session_factory() as session:
        summaries = await summarize_all_participants(
            session, project_id=resolved.id,
        )

    if not summaries:
        await status_msg.edit_text("üì≠ –ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        return

    parts: list[str] = ["üë• <b>–í–∫–ª–∞–¥ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞</b>\n"]
    for s in summaries:
        parts.append(
            f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            f"üë§ <b>{s['user_name']}</b> ({s['message_count']} —Å–æ–æ–±—â.)\n\n"
            f"{s['summary']}"
        )

    text = "\n\n".join(parts)
    # Telegram message limit is ~4096 chars; split if needed
    if len(text) > 4000:
        # Send in chunks per participant
        await status_msg.edit_text(parts[0])
        for part in parts[1:]:
            full_part = part.strip()
            if full_part:
                await message.answer(full_part)
    else:
        try:
            await status_msg.edit_text(text)
        except Exception:
            await message.answer(text)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Voice message handler
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(F.voice)
async def handle_voice_message(message: TgMessage, bot: Bot, **kwargs) -> None:
    """
    Handle incoming voice messages.

    1. Download the voice file from Telegram
    2. Transcribe via Whisper
    3. Store the message with transcribed text
    4. Create an embedding
    """
    tg_user = message.from_user
    if tg_user is None:
        return

    voice = message.voice
    if voice is None:
        return

    silent = kwargs.get("gate_silent", False)
    user_id, project_id = await _resolve_project_for_storage(message)

    # Download and transcribe
    file_id = voice.file_id
    transcribed = None

    if is_ai_configured():
        try:
            file = await bot.get_file(file_id)
            if file.file_path:
                result = await bot.download_file(file.file_path)
                if result:
                    audio_bytes = result.read()
                    transcribed = await process_voice(
                        audio_bytes, filename="voice.ogg"
                    )
        except Exception as e:
            logger.error("Voice download/transcription failed: %s", e)

    # Store the message
    await _store_and_embed_message(
        project_id=project_id,
        user_id=user_id,
        chat_id=str(message.chat.id),
        message_id=str(message.message_id),
        message_type=MessageType.VOICE,
        raw_text=None,
        file_ref=file_id,
        transcribed_text=transcribed,
    )

    # Reply (skip when gate_silent ‚Äî group message not directed at bot)
    if silent:
        return
    if transcribed:
        await message.reply(
            f"üé§ <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n{transcribed}"
        )
    else:
        await message.reply(
            "üé§ –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ."
            + ("" if is_ai_configured() else "\n‚ö†Ô∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (AI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω).")
        )


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Photo/image message handler
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(F.photo)
async def handle_photo_message(message: TgMessage, bot: Bot, **kwargs) -> None:
    """
    Handle incoming photo messages.

    1. Get the largest photo resolution
    2. Download the image from Telegram
    3. Describe via GPT-4 Vision
    4. Store the message with AI description
    5. Create an embedding
    """
    tg_user = message.from_user
    if tg_user is None:
        return

    photos = message.photo
    if not photos:
        return

    # Get the largest photo
    photo = photos[-1]
    caption = message.caption

    silent = kwargs.get("gate_silent", False)
    user_id, project_id = await _resolve_project_for_storage(message)

    # Download and describe
    file_id = photo.file_id
    description = None

    if is_ai_configured():
        try:
            file = await bot.get_file(file_id)
            if file.file_path:
                result = await bot.download_file(file.file_path)
                if result:
                    image_bytes = result.read()
                    description = await process_image(
                        image_bytes, caption=caption
                    )
        except Exception as e:
            logger.error("Photo download/description failed: %s", e)

    # Combine caption + AI description
    transcribed = description
    if caption and description:
        transcribed = f"{caption}\n\n[AI –æ–ø–∏—Å–∞–Ω–∏–µ]: {description}"
    elif caption and not description:
        transcribed = caption

    # Store the message
    await _store_and_embed_message(
        project_id=project_id,
        user_id=user_id,
        chat_id=str(message.chat.id),
        message_id=str(message.message_id),
        message_type=MessageType.IMAGE,
        raw_text=caption,
        file_ref=file_id,
        transcribed_text=transcribed,
    )

    # Reply (skip when gate_silent ‚Äî group message not directed at bot)
    if silent:
        return
    if description:
        reply = f"üì∏ <b>–û–ø–∏—Å–∞–Ω–∏–µ —Ñ–æ—Ç–æ:</b>\n{description}"
    elif caption:
        reply = "üì∏ –§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ."
    else:
        reply = (
            "üì∏ –§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ."
            + ("" if is_ai_configured() else "\n‚ö†Ô∏è –û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ (AI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω).")
        )

    await message.reply(reply)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Text message storage (runs on all text messages for embedding)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


@router.message(F.text & ~F.text.startswith("/"), flags={"store_message": True})
async def store_text_message(message: TgMessage, **kwargs) -> None:
    """
    Store every incoming text message for future RAG/embedding use.

    In group chats, messages that are NOT directed at the bot arrive
    with ``gate_silent=True`` (set by MentionGateMiddleware).  These are
    stored silently ‚Äî no reply, no interaction ‚Äî so the RAG system and
    participant-summary feature have full conversation history.

    Note: Commands are excluded at the filter level (not just inside the
    handler body) so that they can be matched by routers registered later
    (e.g. report_router for /report, /status, /nextstage, etc.).
    """
    tg_user = message.from_user
    if tg_user is None:
        return

    text = message.text or ""

    # Skip very short messages (single characters, etc.)
    if len(text.strip()) < 3:
        return

    user_id, project_id = await _resolve_project_for_storage(message)

    await _store_and_embed_message(
        project_id=project_id,
        user_id=user_id,
        chat_id=str(message.chat.id),
        message_id=str(message.message_id),
        message_type=MessageType.TEXT,
        raw_text=text,
        file_ref=None,
        transcribed_text=text,
    )
