# â”€â”€ Database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
POSTGRES_DB=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# â”€â”€ Telegram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# â”€â”€ AI / LLM Provider â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Provider type: "azure" | "openai" | "openai_compatible"
#   azure             â€” Azure OpenAI (Entra ID or API key)
#   openai            â€” Standard OpenAI API
#   openai_compatible â€” Kimi K2.5, DeepSeek, Groq, Mistral, etc.
AI_PROVIDER=azure

# â”€â”€ Azure OpenAI (when AI_PROVIDER=azure) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Auth: set API_KEY for key-based auth, or leave empty for Microsoft Entra ID
#   Entra ID uses DefaultAzureCredential (az login, managed identity, etc.)
#   Requires: pip install azure-identity
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-10-21
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small
AZURE_OPENAI_WHISPER_DEPLOYMENT=whisper

# â”€â”€ Generic provider settings (when AI_PROVIDER=openai or openai_compatible) â”€â”€
# API key for the provider
AI_API_KEY=
# Base URL (required only for openai_compatible)
# Examples:
#   Ollama:      http://localhost:11434/v1
#   DeepSeek:    https://api.deepseek.com
#   Groq:        https://api.groq.com/openai/v1
#   Together:    https://api.together.xyz/v1
AI_BASE_URL=
AI_CHAT_MODEL=gpt-4o
AI_EMBEDDING_MODEL=text-embedding-3-small
AI_WHISPER_MODEL=whisper-1

# Separate Whisper/STT endpoint (optional â€” if STT runs on a different server)
AI_WHISPER_BASE_URL=
AI_WHISPER_API_KEY=

# Separate Embedding endpoint (optional â€” if embeddings use a different provider)
# Example: Local Ollama for BGE-M3 embeddings while chat uses Groq
AI_EMBEDDING_BASE_URL=
AI_EMBEDDING_API_KEY=

# Embedding vector dimensions (must match your embedding model)
# text-embedding-3-small: 1536    text-embedding-3-large: 3072 â†’ 1536
# BGE-M3: 1024                    Qwen3-Embedding: 1024
AI_EMBEDDING_DIMENSIONS=1536

# â”€â”€ Ollama (self-hosted embeddings, free) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Only for BGE-M3 embeddings (fast on CPU, no GPU needed):
#
# 1. Start Ollama: docker compose --profile ollama up -d
# 2. Pull model:  docker compose exec ollama ollama pull bge-m3
# 3. Set: AI_EMBEDDING_BASE_URL=http://localhost:11434/v1
#         AI_EMBEDDING_API_KEY=ollama
#         AI_EMBEDDING_MODEL=bge-m3
#         AI_EMBEDDING_DIMENSIONS=1024

# â”€â”€ Best Free Combo (recommended) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Chat:       Groq free tier (Llama 3.3 70B, fast, 30 req/min)
# Embeddings: Local Ollama BGE-M3 (free, fast on CPU)
# Whisper:    Groq free tier (instant STT)
#
# Setup:
#   1. Get free Groq key: https://console.groq.com
#   2. Start Ollama: docker compose --profile ollama up -d
#   3. Pull model: docker compose exec ollama ollama pull bge-m3
#   4. Set these values:
#      AI_PROVIDER=openai_compatible
#      AI_API_KEY=gsk_your_groq_key
#      AI_BASE_URL=https://api.groq.com/openai/v1
#      AI_CHAT_MODEL=llama-3.3-70b-versatile
#      AI_EMBEDDING_MODEL=bge-m3
#      AI_EMBEDDING_DIMENSIONS=1024
#      AI_EMBEDDING_BASE_URL=http://localhost:11434/v1
#      AI_EMBEDDING_API_KEY=ollama
#      AI_WHISPER_MODEL=whisper-large-v3
#      AI_WHISPER_BASE_URL=https://api.groq.com/openai/v1
#      AI_WHISPER_API_KEY=gsk_your_groq_key

# â”€â”€ App â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_LEVEL=INFO
DEBUG=false

# â”€â”€ Admin â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Comma-separated Telegram user IDs that can use /addbot, /listbots, /removebot
# Find your ID: message @userinfobot on Telegram
ADMIN_TELEGRAM_IDS=

# â”€â”€ WhatsApp Business Cloud API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Get these from Meta Business Suite â†’ WhatsApp â†’ API Setup
# See: https://developers.facebook.com/docs/whatsapp/cloud-api/get-started
WHATSAPP_PHONE_NUMBER_ID=
WHATSAPP_ACCESS_TOKEN=
WHATSAPP_APP_SECRET=
WHATSAPP_VERIFY_TOKEN=your_custom_verify_token
# Emoji reaction on message receipt (leave empty to disable)
WHATSAPP_ACK_EMOJI=ðŸ‘€

# â”€â”€ Mention Gating (group chats) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# When True, bot only responds in groups when @mentioned or replied to
# Inspired by OpenClaw's requireMention pattern
MENTION_GATE_ENABLED=true
# Extra mention patterns (comma-separated, case-insensitive regexes)
# Example: @renovbot,Ñ€ÐµÐ¼Ð¾Ð½Ñ‚ Ð±Ð¾Ñ‚
MENTION_GATE_PATTERNS=

# â”€â”€ Skills (AI prompt management) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Custom skills directory (default: project_root/skills/)
# Skills are SKILL.md files loaded at startup â€” see skills/ for examples
SKILLS_DIR=
